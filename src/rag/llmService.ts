import { ChatOpenAI } from "@langchain/openai";
import { PromptTemplate } from "@langchain/core/prompts";
import { Document } from "@langchain/core/documents";

export class LLMService {
    private llm: ChatOpenAI;

    constructor() {
        this.llm = new ChatOpenAI({
            openAIApiKey: process.env.OPENAI_API_KEY,
            modelName: "gpt-4o-mini", // Cost-effective model
            temperature: 0.7, // Some creativity for jokes
        });
    }

    /**
     * Generate a personalized joke response based on retrieved context
     */
    async generateJokeResponse(
        userName: string,
        userMessage: string,
        retrievedJokes: Document[],
        conversationStage: string
    ): Promise<string> {

        // Create context from retrieved jokes
        const jokesContext = retrievedJokes.map((doc, index) =>
            `${index + 1}. ${doc.pageContent} (Category: ${doc.metadata.category}, Difficulty: ${doc.metadata.difficulty})`
        ).join('\n');

        const prompt = PromptTemplate.fromTemplate(`
–¢–∏ - –¥—Ä—É–∂–µ–ª—é–±–Ω–∏–π –±–æ—Ç-–∂–∞—Ä—Ç—ñ–≤–Ω–∏–∫, —è–∫–∏–π —Ä–æ–∑–º–æ–≤–ª—è—î —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é. 
–¢–≤–æ—î –∑–∞–≤–¥–∞–Ω–Ω—è - –ø–µ—Ä—Å–æ–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ –≤—ñ–¥–ø–æ–≤—ñ—Å—Ç–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É.

–ö–û–ù–¢–ï–ö–°–¢ –ñ–ê–†–¢–Ü–í:
{jokesContext}

–Ü–ù–§–û–†–ú–ê–¶–Ü–Ø –ü–†–û –ö–û–†–ò–°–¢–£–í–ê–ß–ê:
- –Ü–º'—è: {userName}
- –ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è: {userMessage}
- –ï—Ç–∞–ø —Ä–æ–∑–º–æ–≤–∏: {conversationStage}

–Ü–ù–°–¢–†–£–ö–¶–Ü–á:
1. –í–∏–∫–æ—Ä–∏—Å—Ç–∞–π –Ω–∞–π–±—ñ–ª—å—à —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏–π –∂–∞—Ä—Ç –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
2. –ê–¥–∞–ø—Ç—É–π –≤—ñ–¥–ø–æ–≤—ñ–¥—å –ø—ñ–¥ —ñ–º'—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
3. –ó—Ä–æ–±–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –ø—Ä–∏—Ä–æ–¥–Ω–æ—é —Ç–∞ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ—é
4. –î–æ–¥–∞–π –µ–º–æ–¥–∑—ñ –¥–ª—è –≤–µ—Å–µ–ª–æ—â—ñ–≤
5. –ó–∞–ø–∏—Ç–∞–π —á–∏ —Ö–æ—á–µ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á —â–µ –æ–¥–∏–Ω –∂–∞—Ä—Ç

–ü–†–ò–ö–õ–ê–î –í–Ü–î–ü–û–í–Ü–î–Ü:
"[–∂–∞—Ä—Ç –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É] üòÑ
–•–æ—á–µ—à —â–µ –æ–¥–∏–Ω?"

–í–Ü–î–ü–û–í–Ü–î–¨:
`);

        const formattedPrompt = await prompt.format({
            jokesContext: jokesContext || "–ñ–∞—Ä—Ç—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ñ",
            userName,
            userMessage,
            conversationStage
        });

        const response = await this.llm.invoke(formattedPrompt);
        console.log("üìä [DEBUG] Raw LLM response:", response.content);
        return response.content as string;
    }

    /**
     * Generate a greeting response
     */
    async generateGreeting(userName?: string): Promise<string> {
        console.log("üéØ [DEBUG] Generating greeting for:", userName || "unknown user");

        if (userName) {
            // User name is known - personalized greeting
            const prompt = PromptTemplate.fromTemplate(`
–¢–∏ - –¥—Ä—É–∂–µ–ª—é–±–Ω–∏–π –±–æ—Ç-–∂–∞—Ä—Ç—ñ–≤–Ω–∏–∫. –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑–≤—É—Ç—å {userName}.

–ü—Ä–∏–≤—ñ—Ç–∞–π—Å—è –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ –∑ {userName}, —Å–∫–∞–∂–∏ —â–æ —Ä–∞–¥–∏–π –∑–Ω–∞–π–æ–º—Å—Ç–≤—É —Ç–∞ –∑–∞–ø—Ä–æ–ø–æ–Ω—É–π —Ä–æ–∑–ø–æ–≤—ñ—Å—Ç–∏ –∂–∞—Ä—Ç.
–í–∏–∫–æ—Ä–∏—Å—Ç–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫—É –º–æ–≤—É —Ç–∞ –µ–º–æ–¥–∑—ñ.

–í–Ü–î–ü–û–í–Ü–î–¨:
`);

            const formattedPrompt = await prompt.format({ userName });
            const response = await this.llm.invoke(formattedPrompt);
            console.log("üìä [DEBUG] Personalized greeting response:", response.content);
            return response.content as string;
        } else {
            // User name is unknown - ask for name
            const prompt = PromptTemplate.fromTemplate(`
–¢–∏ - –¥—Ä—É–∂–µ–ª—é–±–Ω–∏–π –±–æ—Ç-–∂–∞—Ä—Ç—ñ–≤–Ω–∏–∫. –Ü–º'—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –Ω–µ–≤—ñ–¥–æ–º–µ.

–ü—Ä–∏–≤—ñ—Ç–∞–π—Å—è –¥—Ä—É–∂–µ–ª—é–±–Ω–æ —Ç–∞ –∑–∞–ø–∏—Ç–∞–π —è–∫ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑–≤—É—Ç—å.
–í–∏–∫–æ—Ä–∏—Å—Ç–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫—É –º–æ–≤—É —Ç–∞ –µ–º–æ–¥–∑—ñ.

–í–Ü–î–ü–û–í–Ü–î–¨:
`);

            const formattedPrompt = await prompt.format({});
            const response = await this.llm.invoke(formattedPrompt);
            console.log("üìä [DEBUG] Name request response:", response.content);
            return response.content as string;
        }
    }

    /**
     * Generate a farewell response
     */
    async generateFarewell(userName: string, jokesCount: number): Promise<string> {
        const prompt = PromptTemplate.fromTemplate(`
–¢–∏ - –¥—Ä—É–∂–µ–ª—é–±–Ω–∏–π –±–æ—Ç-–∂–∞—Ä—Ç—ñ–≤–Ω–∏–∫. –ü–æ–ø—Ä–æ—â–∞–π—Å—è –∑ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é.

–Ü–ù–§–û–†–ú–ê–¶–Ü–Ø:
- –Ü–º'—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞: {userName}
- –ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–æ–∑–∫–∞–∑–∞–Ω–∏—Ö –∂–∞—Ä—Ç—ñ–≤: {jokesCount}

–ó—Ä–æ–±–∏ –ø—Ä–æ—â–∞–Ω–Ω—è –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∏–º, –ø–æ–¥—è–∫—É–π –∑–∞ —Å–ø—ñ–ª–∫—É–≤–∞–Ω–Ω—è —Ç–∞ –¥–æ–¥–∞–π –µ–º–æ–¥–∑—ñ.

–í–Ü–î–ü–û–í–Ü–î–¨:
`);

        const formattedPrompt = await prompt.format({
            userName,
            jokesCount: jokesCount.toString()
        });

        const response = await this.llm.invoke(formattedPrompt); console.log("üìä [DEBUG] Raw LLM response:", response.content);
        return response.content as string;
    }

    /**
     * Analyze user intent with conversation context
     */
    async analyzeUserIntentWithContext(
        userMessage: string,
        conversationHistory: string[],
        conversationStage: string,
        userName?: string
    ): Promise<{
        intent: 'want_joke' | 'dont_want_joke' | 'greeting' | 'farewell' | 'provide_name' | 'unclear';
        confidence: number;
        extractedName?: string;
        reasoning?: string;
    }> {
        const contextString = conversationHistory.length > 0
            ? conversationHistory.slice(-5).join('\n- ') // Last 5 messages
            : "–ù–µ–º–∞—î –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó —ñ—Å—Ç–æ—Ä—ñ—ó";

        const prompt = PromptTemplate.fromTemplate(`
–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—É —Ä–æ–∑–º–æ–≤–∏.

–ü–û–¢–û–ß–ù–ï –ü–û–í–Ü–î–û–ú–õ–ï–ù–ù–Ø: "{userMessage}"

–ö–û–ù–¢–ï–ö–°–¢ –†–û–ó–ú–û–í–ò:
- –ï—Ç–∞–ø: {conversationStage}
- –Ü–º'—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞: {userName}
- –Ü—Å—Ç–æ—Ä—ñ—è –æ—Å—Ç–∞–Ω–Ω—ñ—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å:
{contextString}

–ú–æ–∂–ª–∏–≤—ñ –Ω–∞–º—ñ—Ä–∏:
- want_joke: —Ö–æ—á–µ –∂–∞—Ä—Ç (—Ç–∞–∫, –¥–∞–≤–∞–π, —Ö–æ—á—É, —â–µ –æ–¥–∏–Ω)
- dont_want_joke: –Ω–µ —Ö–æ—á–µ –∂–∞—Ä—Ç (–Ω—ñ, –¥–æ—Å–∏—Ç—å, —Å—Ç–æ–ø)
- greeting: –≤—ñ—Ç–∞—î—Ç—å—Å—è (–ø—Ä–∏–≤—ñ—Ç, hello, –¥–æ–±—Ä–∏–π –¥–µ–Ω—å)
- farewell: –ø—Ä–æ—â–∞—î—Ç—å—Å—è (–¥–æ –ø–æ–±–∞—á–µ–Ω–Ω—è, –±—É–≤–∞–π)
- provide_name: –Ω–∞–¥–∞—î —ñ–º'—è (–º–µ–Ω–µ –∑–≤—É—Ç—å, —è, –º–æ—î —ñ–º'—è)
- unclear: –Ω–µ–∑—Ä–æ–∑—É–º—ñ–ª–æ

–í–ê–ñ–õ–ò–í–û: –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π –¢–Ü–õ–¨–ö–ò —á–∏—Å—Ç–∏–º JSON –±–µ–∑ markdown –±–ª–æ–∫—ñ–≤!

–§–æ—Ä–º–∞—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ:
{{
  "intent": "–Ω–∞–º—ñ—Ä",
  "confidence": 0.95,
  "extractedName": "—ñ–º'—è –∞–±–æ null",
  "reasoning": "–∫–æ—Ä–æ—Ç–∫–µ –ø–æ—è—Å–Ω–µ–Ω–Ω—è —á–æ–º—É —Ç–∞–∫–∏–π –Ω–∞–º—ñ—Ä"
}}
`);

        console.log("üéØ [DEBUG] Analyzing intent with context for:", userMessage);
        const formattedPrompt = await prompt.format({
            userMessage,
            contextString,
            conversationStage,
            userName: userName || "–Ω–µ–≤—ñ–¥–æ–º–µ"
        });
        const response = await this.llm.invoke(formattedPrompt);
        console.log("üìä [DEBUG] Contextual analysis response:", response.content);

        try {
            let cleanResponse = response.content as string;
            cleanResponse = cleanResponse.replace(/```json\s*/g, '').replace(/```\s*/g, '').trim();

            console.log("üßπ [DEBUG] Cleaned contextual response:", cleanResponse);
            const parsed = JSON.parse(cleanResponse);
            console.log("‚úÖ [DEBUG] Parsed contextual intent:", parsed);
            return parsed;
        } catch (error) {
            console.error("‚ùå Failed to parse contextual LLM response:", error);
            console.error("üìÑ Raw response:", response.content);
            return {
                intent: 'unclear',
                confidence: 0.3,
                reasoning: "–ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ"
            };
        }
    }

    /**
     * Analyze user intent from their message (simple version)
     */
    async analyzeUserIntent(userMessage: string): Promise<{
        intent: 'want_joke' | 'dont_want_joke' | 'greeting' | 'farewell' | 'provide_name' | 'unclear';
        confidence: number;
        extractedName?: string;
    }> {
        const prompt = PromptTemplate.fromTemplate(`
–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —Ç–∞ –≤–∏–∑–Ω–∞—á –π–æ–≥–æ –Ω–∞–º—ñ—Ä.

–ü–û–í–Ü–î–û–ú–õ–ï–ù–ù–Ø: "{userMessage}"

–ú–æ–∂–ª–∏–≤—ñ –Ω–∞–º—ñ—Ä–∏:
- want_joke: —Ö–æ—á–µ –∂–∞—Ä—Ç (—Ç–∞–∫, –¥–∞–≤–∞–π, —Ö–æ—á—É, —â–µ –æ–¥–∏–Ω)
- dont_want_joke: –Ω–µ —Ö–æ—á–µ –∂–∞—Ä—Ç (–Ω—ñ, –¥–æ—Å–∏—Ç—å, —Å—Ç–æ–ø)
- greeting: –≤—ñ—Ç–∞—î—Ç—å—Å—è (–ø—Ä–∏–≤—ñ—Ç, hello, –¥–æ–±—Ä–∏–π –¥–µ–Ω—å)
- farewell: –ø—Ä–æ—â–∞—î—Ç—å—Å—è (–¥–æ –ø–æ–±–∞—á–µ–Ω–Ω—è, –±—É–≤–∞–π)
- provide_name: –Ω–∞–¥–∞—î —ñ–º'—è (–º–µ–Ω–µ –∑–≤—É—Ç—å, —è, –º–æ—î —ñ–º'—è)
- unclear: –Ω–µ–∑—Ä–æ–∑—É–º—ñ–ª–æ

–Ø–∫—â–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –Ω–∞–¥–∞—î —ñ–º'—è, –≤–∏—Ç—è–≥–Ω–∏ –π–æ–≥–æ.

–í–ê–ñ–õ–ò–í–û: –í—ñ–¥–ø–æ–≤—ñ–¥–∞–π –¢–Ü–õ–¨–ö–ò —á–∏—Å—Ç–∏–º JSON –±–µ–∑ markdown –±–ª–æ–∫—ñ–≤!

–§–æ—Ä–º–∞—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ:
{{
  "intent": "–Ω–∞–º—ñ—Ä",
  "confidence": 0.95,
  "extractedName": "—ñ–º'—è –∞–±–æ null"
}}
`);

        console.log("üéØ [DEBUG] Analyzing intent for:", userMessage);
        const formattedPrompt = await prompt.format({ userMessage });
        const response = await this.llm.invoke(formattedPrompt);
        console.log("üìä [DEBUG] Raw LLM response:", response.content);

        try {
            // Clean the response from markdown code blocks
            let cleanResponse = response.content as string;
            cleanResponse = cleanResponse.replace(/```json\s*/g, '').replace(/```\s*/g, '').trim();

            console.log("üßπ [DEBUG] Cleaned response:", cleanResponse);
            const parsed = JSON.parse(cleanResponse);
            console.log("‚úÖ [DEBUG] Parsed intent:", parsed);
            return parsed;
        } catch (error) {
            console.error("‚ùå Failed to parse LLM response:", error);
            console.error("üìÑ Raw response:", response.content);
            return {
                intent: 'unclear',
                confidence: 0.5
            };
        }
    }

    /**
     * Generate a contextual response when no jokes are found
     */
    async generateNoJokesResponse(userName: string, userQuery: string): Promise<string> {
        const prompt = PromptTemplate.fromTemplate(`
–ö–æ—Ä–∏—Å—Ç—É–≤–∞—á {userName} –∑–∞–ø–∏—Ç–∞–≤ –ø—Ä–æ –∂–∞—Ä—Ç–∏, –∞–ª–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –∂–∞—Ä—Ç—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.
–ó–∞–ø–∏—Ç: "{userQuery}"

–í–∏–±–∞—á –ø–µ—Ä–µ–¥ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º, –∑–∞–ø—Ä–æ–ø–æ–Ω—É–π –∑–∞–≥–∞–ª—å–Ω–∏–π –∂–∞—Ä—Ç –∞–±–æ –ø–æ–ø—Ä–æ—Å–∏ —É—Ç–æ—á–Ω–∏—Ç–∏ —â–æ –≤—ñ–Ω —Ö–æ—á–µ.
–í—ñ–¥–ø–æ–≤—ñ–¥–∞–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é –∑ –µ–º–æ–¥–∑—ñ.

–í–Ü–î–ü–û–í–Ü–î–¨:
`);

        const formattedPrompt = await prompt.format({ userName, userQuery });
        const response = await this.llm.invoke(formattedPrompt); console.log("üìä [DEBUG] Raw LLM response:", response.content);
        return response.content as string;
    }
} 